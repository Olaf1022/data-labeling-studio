{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Transfer learning with PyTorch\n",
    "\n",
    "\n",
    "In this tutorial you will learn how to configure and connect your own PyTorch model to Label Studio.\n",
    "\n",
    "First you need to install pyheartex SDK that provides all endpoints for Label Studio to ML backend communication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! pip install pyheartex"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Declare PyTorch data loaders that convert Label Studio's completions to neural network input feed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class ImageClassifierDataset(Dataset):\n",
    "        \n",
    "    def __init__(self, image_urls, image_classes):\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        self.classes = list(set(image_classes))\n",
    "        self.class_to_label = {c: i for i, c in enumerate(self.classes)}\n",
    "        \n",
    "        self.image_size = 224\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.Resize(self.image_size),\n",
    "            transforms.CenterCrop(self.image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        for image_url, image_class in zip(image_urls, image_classes):\n",
    "            image = self._get_image_from_url(image_url)\n",
    "            transformed_image = self.transforms(image)\n",
    "            self.images.append(transformed_image)\n",
    "            \n",
    "            label = self.class_to_label[image_class]\n",
    "            self.labels.append(label)\n",
    "            \n",
    "    def _get_image_from_url(self, url):\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.images[index], self.labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's create a simple convolutional neural network image classifier based on pretrained ResNet18 model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ImageClassifier(object):\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        \n",
    "        self.model = self.model.to(device)\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9)\n",
    "        \n",
    "        # Decay LR by a factor of 0.1 every 7 epochs\n",
    "        self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=7, gamma=0.1)\n",
    "    \n",
    "    def save(self, path):\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "    \n",
    "    def load(self, path):\n",
    "        self.model.load_state_dict(torch.load(path))\n",
    "        self.model.eval()\n",
    "        \n",
    "    def train(self, dataloader, num_epochs=25):\n",
    "        since = time.time()\n",
    "\n",
    "        self.model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "            print('-' * 10)\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0    \n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                self.scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "\n",
    "            print('Train Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "        print()\n",
    "    \n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "        return self.model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next step is to override API methods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from htx.base_model import BaseModel\n",
    "\n",
    "\n",
    "class ImageClassifierAPI(BaseModel):\n",
    "    \n",
    "    INPUT_TYPES = ('Image',)\n",
    "    OUTPUT_TYPES = ('Choices',)\n",
    "    \n",
    "    def load(self, resources, **kwargs):\n",
    "        \"\"\"\n",
    "        This method load model weights and any additional parameters into memory for further inference\n",
    "        :param resources: dict-like object taken from training output\n",
    "        :param kwargs: any additional parameters\n",
    "        :return: \n",
    "        \"\"\"\n",
    "        self.model = ImageClassifier(resources['num_classes'])\n",
    "        self.model.load(resources['model_path'])\n",
    "        self.labels = resources['labels']\n",
    "        \n",
    "    def load_input_images(self, tasks):\n",
    "        image_urls = [task['input'][0] for task in tasks]\n",
    "        \n",
    "    def predict(self, tasks, **kwargs):\n",
    "        pass\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally the training script is defined by a separate function that could lie in a separate environment. \n",
    "The only one convention is that it should consume task iterator as input and produce dict-like object of train resources used later by `load()` function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_image_classifier(input_tasks, output_dir, **kwargs):\n",
    "    \n",
    "    batch_size = 32\n",
    "    num_epochs = 25     \n",
    "    \n",
    "    image_urls, image_classes = [], []\n",
    "    for task in input_tasks:\n",
    "        image_url = task['input'][0]\n",
    "        image_class = task['output'][0]['value']['choices'][0]\n",
    "        image_urls.append(image_url)\n",
    "        image_classes.append(image_class)\n",
    "        \n",
    "    dataset = ImageClassifierDataset(image_urls, image_classes)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    \n",
    "    model = ImageClassifier(len(dataset.classes))\n",
    "    model.train(dataloader, num_epochs)\n",
    "    \n",
    "    model.save(os.path.join(output_dir, 'model.pt'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now the model is ready, it's time to launch ML backend server.\n",
    "First of all, let's create launch script called `wsgi.py`:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "from htx import app, init_model_server\n",
    "from my_image_classifier import ImageClassifierAPI, train_image_classifier\n",
    "\n",
    "\n",
    "init_model_server(\n",
    "    create_model_func=ImageClassifierAPI,\n",
    "    train_script=train_image_classifier,\n",
    "    image_dir='~/.heartex/images',\n",
    "    redis_queue=os.environ.get('RQ_QUEUE_NAME', 'default'),\n",
    "    redis_host=os.environ.get('REDIS_HOST', 'localhost'),\n",
    "    redis_port=os.environ.get('REDIS_PORT', 6379),\n",
    ")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--port', dest='port', default='9090')\n",
    "    args = parser.parse_args()\n",
    "    app.run(host='localhost', port=args.port, debug=True)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now you have two possibilities depending on what scenario you'd expect from interacting with ML backend.\n",
    "\n",
    "## Use Machine Learning backend only for prediction\n",
    "\n",
    "If you want to run ML backend only for inference, i.e. getting the autolabels from pretrained model predictions, you can just launch the created script:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! python wsgi.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It automatically starts server on `http://localhost:9090`. To connect Label Studio app to the running server, initialize new project as the following:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! label-studio start new_project --init --ml-backend-url http://localhost:9090 --template image_classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "That's all. Once you start labeling, you should be able to see the predicted image classes & ML backend server logs.\n",
    "\n",
    "## Use Machine learning backend for prediction and retraining (active learning)\n",
    "This scenario is suitable if you have already model trained to predict your target images, so that you can see prelabeling results and play with low-confident samples.\n",
    "However if you want to keep your model constantly retraining after labeling some part of a dataset (which is a common case scenario with _active learning_), then you have to configure your server not only for inference but also for training.\n",
    "Hopefully, pyheartex SDK provides a facility to do this without cumbersome coding by using RQ library. All you need is to start Redis server, RQ workers and link them to your `wsgi.py` via `RQ_QUEUE_NAME`, `REDIS_HOST`, `REDIS_PORT` parameters.\n",
    "\n",
    "If you don't have time to launch RQ stack by yourself, you can leverage an off-the-shell docker configs. \n",
    "First make sure you have docker compose and docker installed on your system.\n",
    "Then clone Git repo:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! git clone https://github.com/heartexlabs/label-studio-ml-backend"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " \n",
    "Copy your files `wsgi.py` and `my_model.py` into the root directory `label-studio-ml-backend/`. Then build and run server:\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! docker-compose up"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "That's it. If everything is set, you can connect run Label Studio connected to your ML backend the same as above"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! label-studio start new_project --init --ml-backend-url http://localhost:9090 --template image_classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Go to [Label Studio Machine Learning page](http://localhost:8080/ml.html) to check if everything is connected."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}